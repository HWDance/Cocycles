{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063bf033-eaf6-4bb3-9ea8-716d1e3b6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import (\n",
    "    Distribution, Normal, Laplace, Cauchy, Gamma, Uniform\n",
    ")\n",
    "from csuite import SCMS, SCM_DIMS, SCM_MASKS\n",
    "from architectures import get_stock_transforms\n",
    "from zuko.flows import UnconditionalDistribution\n",
    "from causalflows.flows import CausalFlow\n",
    "from causal_cocycle.causalflow_helper import select_and_train_flow, sample_do, sample_cf\n",
    "from causal_cocycle.helper_functions import ks_statistic, wasserstein1_repeat, rmse\n",
    "\n",
    "from zuko.flows.autoregressive import MaskedAutoregressiveTransform\n",
    "from zuko.flows import UnconditionalDistribution\n",
    "from zuko.transforms import MonotonicRQSTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13906421-ac6f-4ff8-b3ee-c81319183695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.transforms import Transform\n",
    "class ShiftTransform(Transform):\n",
    "    bijective = True\n",
    "    sign = +1\n",
    "\n",
    "    def __init__(self, b):\n",
    "        # b will be a tensor of shape (batch,1)\n",
    "        super().__init__(cache_size=0)\n",
    "        self.b = b\n",
    "\n",
    "    def _call(self, x):\n",
    "        # x: (B,), b: (B,1) ⇒ squeeze to (B,)\n",
    "        shift = self.b.squeeze(-1)\n",
    "        return x + shift\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        shift = self.b.squeeze(-1)\n",
    "        return y - shift\n",
    "\n",
    "    def log_abs_det_jacobian(self, x, y):\n",
    "        # d(x+shift)/dx = 1  ⇒ log|1| = 0\n",
    "        return torch.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70d40a8a-2905-454b-9be4-0241a84d1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_models(\n",
    "    models_dict: dict,\n",
    "    index_dict: dict,\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    noisedist: Distribution,\n",
    "    noisetransform: callable,\n",
    "    sig_noise_ratio: float,\n",
    "    seed: int = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Adapted to work with a joint causal flow in models_dict.\n",
    "    Expects models_dict = {'Flow': (flow, 'flow')},\n",
    "             index_dict  = {'Flow': (idx, 'flow')}.\n",
    "    Returns the same keys: KS_int, CF_RMSE, index under 'Flow'.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    device = X.device\n",
    "    N, D = X.shape\n",
    "    _, P = Y.shape\n",
    "    assert D == 1 and P == 1  # 2D joint (X,Y)\n",
    "\n",
    "    # “true” counterfactual shift ΔY = +1\n",
    "    Z = torch.cat([X, Y], dim=1).to(device)             # shape (N,2)\n",
    "    X_cf = X*0 + 1.0\n",
    "    ΔY_true = Y - X + 1.0 \n",
    "\n",
    "    # “true” interventional Y distribution:\n",
    "    # Y_true = X_cf + U    with U = noisetransform(noisedist.sample)\n",
    "    m = 10**5\n",
    "    # sample X* from Normal(1,1) then +1, and add noise:\n",
    "    Y_true = (\n",
    "        Normal(1, 1).sample((m, D)).to(device)\n",
    "        + 1.0\n",
    "        + noisetransform(noisedist.sample((m, 1)).to(device))\n",
    "    )  # shape (m,1)\n",
    "\n",
    "    results = {}\n",
    "    for name, (flow, _) in models_dict.items():\n",
    "\n",
    "        # ---- interventional estimate via Alg 1 ----\n",
    "        # sample m draws from the *joint* under do(X = 1)\n",
    "        Y_do = sample_do(\n",
    "            flow.to(device),\n",
    "            index=0,\n",
    "            intervention_fn=lambda old: old + 1.0,\n",
    "            sample_shape=torch.Size([m])\n",
    "        )  # shape (m, 2)\n",
    "        Y_int = Y_do[:, 1].unsqueeze(-1)  # shape (m,1)\n",
    "        KS_int = ks_statistic(Y_int[:,0].cpu(), Y_true[:,0].cpu())\n",
    "\n",
    "        # ---- counterfactual via Alg 2 ----\n",
    "        Z_cf = sample_cf(\n",
    "            flow.to(device),\n",
    "            x_obs=Z,\n",
    "            index=0,\n",
    "            intervention_fn=lambda old: old*0 + 1.0\n",
    "        )  # shape (N,2)\n",
    "        ΔY_model = (Z_cf[:,1] - Z[:,1]).unsqueeze(-1)  # (N,1)\n",
    "        CF_RMSE = rmse(Z_cf[:,1].cpu(), ΔY_true[:,0].cpu())\n",
    "\n",
    "        results[name] = {\n",
    "            'KS_int':  KS_int,\n",
    "            'CF_RMSE': CF_RMSE,\n",
    "            'index': index_dict[name][0]\n",
    "        }\n",
    "\n",
    "    # add noise info if you like (mirroring your old script)\n",
    "    results['noise_distribution'] = noisedist.__class__.__name__\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4583a90b-1f63-4cf0-9a99-ee970e7e4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "N = 1000\n",
    "noise_dist = \"normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7dc9253-a53e-4263-8f46-1fcee683cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configs\n",
    "\"\"\"\n",
    "# Experimental set up\n",
    "D,P = 1,1\n",
    "sig_noise_ratio = 1\n",
    "\n",
    "# Model setup\n",
    "width = 32\n",
    "bins = 8\n",
    "\n",
    "\"\"\"\n",
    "Data gen\n",
    "\"\"\"\n",
    "torch.manual_seed(seed)\n",
    "X = Normal(1,1).sample((N,D))\n",
    "X *= 1/(D)**0.5\n",
    "B = torch.ones((D,1))*(torch.linspace(0,D-1,D)<P)[:,None]\n",
    "F = X @ B\n",
    "if noise_dist == \"normal\":\n",
    "    noisedist = Normal(0,1)\n",
    "    noisetransform = lambda x : x\n",
    "elif noise_dist == \"rademacher\": \n",
    "    noisedist = Uniform(-1,1)\n",
    "    noisetransform = lambda x : torch.sign(x)\n",
    "elif noise_dist == \"cauchy\":\n",
    "    noisedist = Cauchy(0,1)\n",
    "    noisetransform = lambda x : x\n",
    "elif noise_dist == \"gamma\":\n",
    "    noisedist = Gamma(1,1)\n",
    "    noisetransform = lambda x : x\n",
    "elif noise_dist == \"inversegamma\":\n",
    "    noisedist = Gamma(1,1)\n",
    "    noisetransform = lambda x : 1/x\n",
    "U = noisetransform(noisedist.sample((N,1)))/sig_noise_ratio**0.5\n",
    "Y = F + U\n",
    "XY = torch.cat([X,Y],dim = 1)\n",
    "\n",
    "\"\"\"\n",
    "Defining list of flows to CV over\n",
    "\"\"\"\n",
    "\n",
    "# shared base distribution\n",
    "baseg = UnconditionalDistribution(\n",
    "    Normal,\n",
    "    loc=torch.zeros(2),\n",
    "    scale=torch.ones(2),\n",
    "    buffer=True,\n",
    ")\n",
    "\n",
    "basel = UnconditionalDistribution(\n",
    "    Laplace,\n",
    "    loc=torch.zeros(2),\n",
    "    scale=torch.ones(2),\n",
    "    buffer=True,\n",
    ")\n",
    "\n",
    "\n",
    "# 1) MAF only, shift linear conditioner\n",
    "maf_shift_only = MaskedAutoregressiveTransform(\n",
    "    features=2,\n",
    "    context=0,\n",
    "    hidden_features=(),   # you can also use () for purely linear shift\n",
    "    univariate=ShiftTransform,  # use our shift‐only bijector\n",
    "    shapes=([1],),              # one shift‐parameter per dimension\n",
    ")\n",
    "flow_shift_only_g = CausalFlow(\n",
    "    transform=[maf_shift_only],\n",
    "    base=baseg,\n",
    ")\n",
    "flow_shift_only_l = CausalFlow(\n",
    "    transform=[maf_shift_only],\n",
    "    base=basel,\n",
    ")\n",
    "\n",
    "# 3) MAF only, shift neural‑net conditioner\n",
    "maf_nn_shift_only = MaskedAutoregressiveTransform(\n",
    "    features=2,\n",
    "    context=0,\n",
    "    hidden_features=(width, width),   # you can also use () for purely linear shift\n",
    "    univariate=ShiftTransform,  # use our shift‐only bijector\n",
    "    shapes=([1],),              # one shift‐parameter per dimension\n",
    ")\n",
    "flow_nn_shift_only_g = CausalFlow(\n",
    "    transform=[maf_nn_shift_only],\n",
    "    base=baseg,\n",
    ")\n",
    "flow_nn_shift_only_l = CausalFlow(\n",
    "    transform=[maf_nn_shift_only],\n",
    "    base=basel,\n",
    ")\n",
    "\n",
    "# 3) MAF only, neural‑net conditioner\n",
    "maf_nn = MaskedAutoregressiveTransform(\n",
    "    features=2,\n",
    "    context=0,\n",
    "    hidden_features=(width, width),  # two hidden layers of size 32\n",
    ")\n",
    "flow_maf_nn_g = CausalFlow(transform=[maf_nn], base=baseg)\n",
    "flow_maf_nn_l = CausalFlow(transform=[maf_nn], base=basel)\n",
    "\n",
    "# 4) MAF → RQS, both neural‑net conditioners\n",
    "maf_nn = MaskedAutoregressiveTransform(\n",
    "    features=2,\n",
    "    context=0,\n",
    "    hidden_features=(width, width),\n",
    ")\n",
    "rqs_nn = MaskedAutoregressiveTransform(\n",
    "    features=2,\n",
    "    context=0,\n",
    "    hidden_features=(width, width),\n",
    "    univariate=MonotonicRQSTransform,\n",
    "    shapes=([bins], [bins], [bins + 1]),\n",
    ")\n",
    "flow_maf_rqs_nn_g = CausalFlow(transform=[maf_nn, rqs_nn], base=baseg)\n",
    "flow_maf_rqs_nn_l = CausalFlow(transform=[maf_nn, rqs_nn], base=basel)\n",
    "\n",
    "# Gaussian + Laplace base flows\n",
    "flows_g = [\n",
    "flow_shift_only_g,\n",
    "flow_nn_shift_only_g,\n",
    "flow_maf_nn_g,\n",
    "flow_maf_rqs_nn_g\n",
    "    ]\n",
    "flows_l = [\n",
    "flow_shift_only_l,\n",
    "flow_nn_shift_only_l,\n",
    "flow_maf_nn_l,\n",
    "flow_maf_rqs_nn_l\n",
    "    ]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "# Gaussian‐base\n",
    "best_g, test_nll_g, idx_g, cv_scores_g = select_and_train_flow(\n",
    "    flows_g,\n",
    "    XY,\n",
    "    train_fraction=1.0,\n",
    "    k_folds=2,\n",
    "    num_epochs=500,\n",
    "    batch_size=128,\n",
    "    lr=1e-2,\n",
    "    device=XY.device\n",
    ")\n",
    "\n",
    "# Laplace‐base\n",
    "best_l, test_nll_l, idx_l, cv_scores_l = select_and_train_flow(\n",
    "    flows_l,\n",
    "    XY,\n",
    "    train_fraction=1.0,\n",
    "    k_folds=2,\n",
    "    num_epochs=500,\n",
    "    batch_size=128,\n",
    "    lr=1e-2,\n",
    "    device=XY.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2740799-7fcd-4141-921c-c0e8d641e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GaussianFlow': {'KS_int': 0.012010008096694946, 'CF_RMSE': 0.024647604674100876, 'index': 0}, 'LaplaceFlow': {'KS_int': 0.11251002550125122, 'CF_RMSE': 0.2849721610546112, 'index': 2}, 'noise_distribution': 'Normal'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluating\n",
    "\"\"\"\n",
    "# 6) Wrap into the same my_models / my_indexes format\n",
    "# --------------------------------------------------------------------------------\n",
    "my_models = {\n",
    "    'GaussianFlow': (best_g, 'flow'),\n",
    "    'LaplaceFlow':  (best_l, 'flow'),\n",
    "}\n",
    "my_indexes = {\n",
    "    'GaussianFlow': (idx_g, 'flow'),\n",
    "    'LaplaceFlow':  (idx_l, 'flow'),\n",
    "}\n",
    "\n",
    "# 7) Evaluate with your original evaluate_models\n",
    "# --------------------------------------------------------------------------------\n",
    "metrics = evaluate_models(\n",
    "    my_models,\n",
    "    my_indexes,\n",
    "    X, Y,\n",
    "    noisedist,\n",
    "    noisetransform,\n",
    "    sig_noise_ratio,\n",
    "    seed=seed\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0edf91a-2f76-42c3-88c5-66f5bd506c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import get_stock_transforms\n",
    "from csuite import generate_2var_linear, _get_noises\n",
    "def generate_2var_linear(\n",
    "    N: int,\n",
    "    seed: int | None = None,\n",
    "    intervention_node: int | None = None,\n",
    "    intervention_fn: callable = None,\n",
    "    intervention_value: float | None = None,\n",
    "    return_u: bool = False,\n",
    "    noise_dists: list[Distribution] = None,\n",
    "    noise_transforms: list[callable] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    2-VAR linear SCM:\n",
    "      u1; x1 = u1\n",
    "      u2; x2 = x1 + u1\n",
    "    noise_dists: list of 2 Distribution objects for u1,u2.\n",
    "    noise_transform: applied to each sampled noise.\n",
    "    \"\"\"\n",
    "    if noise_dists is None or len(noise_dists) != 2:\n",
    "        raise ValueError(\"noise_dists must be a list of length 2\")\n",
    "    u1, u2 = _get_noises(N, 2, noise_dists, noise_transforms, seed)\n",
    "    x1 = u1.clone() + 1\n",
    "    if intervention_node == 1:\n",
    "        x1 = intervention_fn(x1, intervention_value)\n",
    "    x2 = x1 + u2\n",
    "    if intervention_node == 2:\n",
    "        x2 = intervention_fn(x2, intervention_value)\n",
    "    X = torch.cat([x1, x2], dim=1)\n",
    "    if return_u:\n",
    "        return X, torch.cat([u1, u2], dim=1)\n",
    "    return X\n",
    "\n",
    "def evaluate_models_2(\n",
    "    models_dict: dict,\n",
    "    index_dict: dict,\n",
    "    sc_fun: callable,\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    noisedist: Distribution,\n",
    "    noisetransform: callable,\n",
    "    seed: int = None,\n",
    "    N_true: int = 10**5,\n",
    "    intervention_node: int = 1,\n",
    "    intervention_value: float = 1.0,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates each model by comparing its interventional, counterfactual,\n",
    "    and paired-difference estimates to the ground-truth SCM (`sc_fun`).\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    device = X.device\n",
    "    N, d = X.shape\n",
    "    N, p = Y.shape\n",
    "\n",
    "    # --- True paired (Y, Y_cf) via SCM generator ---\n",
    "    torch.manual_seed(seed)\n",
    "    X_obs_true, U = sc_fun(\n",
    "        N_true,\n",
    "        seed=seed,\n",
    "        intervention_node=None,\n",
    "        return_u=True,\n",
    "        noise_dists=[Normal(0,1)] + [noisedist],\n",
    "        noise_transforms = [lambda x : x] + [noisetransform]\n",
    "    )\n",
    "    X_obs_true = X_obs_true.to(device)\n",
    "    torch.manual_seed(seed)\n",
    "    X_cf_true, Ucf = sc_fun(\n",
    "        N_true,\n",
    "        seed=seed,\n",
    "        intervention_node=intervention_node,\n",
    "        intervention_fn = lambda x,a : x+a,\n",
    "        intervention_value=intervention_value,\n",
    "        return_u=True,\n",
    "        noise_dists=[Normal(0,1)] + [noisedist],\n",
    "        noise_transforms = [lambda x : x] + [noisetransform]\n",
    "    )\n",
    "    X_cf_true = X_cf_true.to(device)\n",
    "    # check same noise\n",
    "    assert((U-Ucf).sum()==0)\n",
    "    \n",
    "    # Extract paired Y variables (columns 1 onward)\n",
    "    Y_true = X_obs_true[:, 1:]\n",
    "    Y_cf_true = X_cf_true[:, 1:]\n",
    "    Y_dim = Y_true.shape[1]\n",
    "\n",
    "    # paired-difference\n",
    "    diff_true = Y_cf_true - Y_true\n",
    "\n",
    "    results = {}\n",
    "    with torch.no_grad():\n",
    "        for name, (flow, _) in models_dict.items():\n",
    "            # --- Model paired (Y, Y_cf) via sample_do ---\n",
    "            torch.manual_seed(seed)\n",
    "            X_model = sample_do(\n",
    "                flow.to(device),\n",
    "                index=intervention_node-1,\n",
    "                intervention_fn=lambda old: old,\n",
    "                sample_shape=torch.Size([N_true])\n",
    "            )\n",
    "            torch.manual_seed(seed)\n",
    "            X_cf_model = sample_do(\n",
    "                flow.to(device),\n",
    "                index=intervention_node-1,\n",
    "                intervention_fn=lambda old: old + intervention_value,\n",
    "                sample_shape=torch.Size([N_true])\n",
    "            )\n",
    "            Y_model = X_model[:, 1:]\n",
    "            Y_cf_model = X_cf_model[:, 1:]\n",
    "            diff_model = Y_cf_model - Y_model\n",
    "    \n",
    "            # --- Marginal KS values for each Y dimension ---\n",
    "            w1_vals = [\n",
    "                wasserstein1_repeat(diff_model[:, j].cpu(), diff_true[:, j].cpu())\n",
    "                for j in range(Y_dim)\n",
    "            ]\n",
    "    \n",
    "            # --- Marginal KS values for each Y dimension ---\n",
    "            ks_vals = [\n",
    "                ks_statistic(diff_model[:, j].cpu(), diff_true[:, j].cpu())\n",
    "                for j in range(Y_dim)\n",
    "            ]\n",
    "    \n",
    "            # --- Interventional marginal KS ---\n",
    "            # Reuse Y_cf_model for marginal KS\n",
    "            w1_int_vals = [\n",
    "                wasserstein1_repeat(Y_cf_model[:, j].cpu(), Y_cf_true[:, j].cpu())\n",
    "                for j in range(Y_dim)\n",
    "            ]\n",
    "            ks_int_vals = [\n",
    "                ks_statistic(Y_cf_model[:, j].cpu(), Y_cf_true[:, j].cpu())\n",
    "                for j in range(Y_dim)\n",
    "            ]\n",
    "    \n",
    "            # --- Counterfactual RMSE ---\n",
    "            torch.manual_seed(seed)\n",
    "            X_obs, U = sc_fun(\n",
    "                N,\n",
    "                seed=seed,\n",
    "                intervention_node=None,\n",
    "                return_u=True,\n",
    "                noise_dists=[Normal(0,1)] + [noisedist],\n",
    "                noise_transforms = [lambda x : x] + [noisetransform]\n",
    "            )\n",
    "            X_obs = X_obs.to(device)\n",
    "            Y_obs = X_obs[:, 1:].to(device)\n",
    "            torch.manual_seed(seed)\n",
    "            X_cf, Ucf = sc_fun(\n",
    "                N,\n",
    "                seed=seed,\n",
    "                intervention_node=intervention_node,\n",
    "                intervention_fn = lambda x,a : x+a,\n",
    "                intervention_value=intervention_value,\n",
    "                return_u=True,\n",
    "                noise_dists=[Normal(0,1)] + [noisedist],\n",
    "                noise_transforms = [lambda x : x] + [noisetransform]\n",
    "            )\n",
    "            X_cf = X_cf.to(device)\n",
    "            Y_cf = X_cf[:, 1:]\n",
    "            \n",
    "            Z_cf = sample_cf(\n",
    "                flow.to(device),\n",
    "                x_obs=X_obs,\n",
    "                index=intervention_node - 1,\n",
    "                intervention_fn=lambda old: old + intervention_value\n",
    "            )\n",
    "            rmse_cf_vals = [\n",
    "                rmse(Z_cf[:, 1:][:,j].cpu(), Y_cf[:, j].cpu())\n",
    "                for j in range(Y_dim)\n",
    "            ]\n",
    "            results[name] = {\n",
    "                'KS_CF': ks_vals,\n",
    "                'KS_int': ks_int_vals,\n",
    "                'W1_CF': w1_vals,\n",
    "                'W1_int': w1_int_vals,\n",
    "                'RMSE_CF': rmse_cf_vals,\n",
    "                'index': index_dict[name][0]\n",
    "            }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "190c1ec3-b296-48cc-affd-7978465ff53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GaussianFlow': {'KS_CF': [1.0], 'KS_int': [0.01184999942779541], 'W1_CF': [tensor(0.0240)], 'W1_int': [tensor(0.0328)], 'RMSE_CF': [0.02396257221698761], 'index': 0}, 'LaplaceFlow': {'KS_CF': [0.7042700052261353], 'KS_int': [0.11078000068664551], 'W1_CF': [tensor(0.8956)], 'W1_int': [tensor(0.5245)], 'RMSE_CF': [0.35234159231185913], 'index': 2}}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_models_2(\n",
    "    my_models,\n",
    "    my_indexes,\n",
    "    generate_2var_linear,\n",
    "    X, Y,\n",
    "    noisedist,\n",
    "    noisetransform,\n",
    "    seed = 0,\n",
    "    N_true = 10**5,\n",
    "    intervention_node = 1,\n",
    "    intervention_value = 1.0,\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

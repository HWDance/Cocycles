{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527d3458-c951-4399-9dc5-4ae721968e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assume the following modules are defined in your repository:\n",
    "from causal_cocycle.kernels_new import GaussianKernel\n",
    "from causal_cocycle.regression_functionals import NWFunctional \n",
    "from causal_cocycle.distribution_estimation import ConditionalExpectationRegressor  \n",
    "from causal_cocycle.conditioners_new import NWConditioner  # NWConditioner defined earlier\n",
    "from causal_cocycle.transformers_new import KREpsLayer  # Your KR transformer layer\n",
    "from causal_cocycle.model_new import CocycleModel   # Your CocycleModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078ed3f4-6aac-4700-9eda-41dfa954c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "working KR map function\n",
    "\"\"\"\n",
    "def build_KR_map(X: torch.Tensor, Y: torch.Tensor, \n",
    "                                                   w_src: torch.Tensor = None, w_tgt: torch.Tensor = None, epsilon: float = 1e-8):\n",
    "\n",
    "    # Get weights if not provided\n",
    "    if w_src is None:\n",
    "        n_src = X.numel()\n",
    "        w_src = torch.ones(n_src, device=X.device) / n_src\n",
    "    if w_tgt is None:\n",
    "        n_tgt = Y.numel()\n",
    "        w_tgt = torch.ones(n_tgt, device=Y.device) / n_tgt\n",
    "    \n",
    "    # Sort X and Y first\n",
    "    X_sorted_full, idx_X = torch.sort(X)\n",
    "    Y_sorted_full, idx_Y = torch.sort(Y)\n",
    "    w_src_sorted_full = w_src[idx_X]\n",
    "    w_tgt_sorted_full = w_tgt[idx_Y]\n",
    "    \n",
    "    # Get unique sorted values for X, and sum the weights of duplicates.\n",
    "    X_sorted, inverse_idx_X = torch.unique(X_sorted_full, sorted=True, return_inverse=True)\n",
    "    w_src_sorted = torch.zeros_like(X_sorted, dtype=w_src.dtype)\n",
    "    w_src_sorted = w_src_sorted.scatter_add_(0, inverse_idx_X, w_src_sorted_full)\n",
    "    \n",
    "    # Do the same for Y.\n",
    "    Y_sorted, inverse_idx_Y = torch.unique(Y_sorted_full, sorted=True, return_inverse=True)\n",
    "    w_tgt_sorted = torch.zeros_like(Y_sorted, dtype=w_tgt.dtype)\n",
    "    w_tgt_sorted = w_tgt_sorted.scatter_add_(0, inverse_idx_Y, w_tgt_sorted_full)\n",
    "    \n",
    "    # Normalize the weights.\n",
    "    w_src_sorted = w_src_sorted / w_src_sorted.sum()\n",
    "    w_tgt_sorted = w_tgt_sorted / w_tgt_sorted.sum()\n",
    "    \n",
    "    def S(z):\n",
    "        z = z.double()\n",
    "        if epsilon == 0:\n",
    "            return (z>=0).float()\n",
    "        else:\n",
    "            return torch.where(z < -epsilon, torch.zeros_like(z),\n",
    "                               torch.where(z > epsilon, torch.ones_like(z),\n",
    "                                           (z + epsilon) / (2 * epsilon)))\n",
    "    def F_src(y):\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.tensor(y, device=X_sorted.device)\n",
    "        if y.dim() == 0:\n",
    "            y = y.unsqueeze(0)\n",
    "        if y.dim() == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        X_exp = X_sorted.unsqueeze(0)\n",
    "        S_vals = S(y - X_exp)\n",
    "        return torch.sum(w_src_sorted * S_vals, dim=-1)\n",
    "        \n",
    "    def Q_tgt(t):\n",
    "        if not isinstance(t, torch.Tensor):\n",
    "            t = torch.tensor(t, device=Y_sorted.device)\n",
    "        if t.dim() > 1:\n",
    "            t = t.squeeze(-1)\n",
    "        cumsum = torch.cumsum(w_tgt_sorted, dim=0)\n",
    "        indices = torch.searchsorted(cumsum, t.unsqueeze(1)).squeeze(1)\n",
    "        indices = torch.clamp(indices, 0, Y_sorted.numel()-1)\n",
    "        j = indices-1\n",
    "        j_next = indices\n",
    "        cumsum = torch.concatenate((torch.zeros(1),cumsum))\n",
    "        cumsum_j = cumsum[j+1]\n",
    "        w_j_next = w_tgt_sorted[j_next]\n",
    "        s = (t - cumsum_j) / w_j_next\n",
    "        Y_j_next = Y_sorted[j_next].double()\n",
    "        Y_prev = Y_sorted[torch.clamp(j, min=0)].double()\n",
    "        return Y_j_next - epsilon + 2 * epsilon * s\n",
    "        \n",
    "    def KR(y):\n",
    "        t_val = F_src(y)\n",
    "        return Q_tgt(t_val)\n",
    "    return KR, F_src, Q_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8303bb2b-329c-4831-8392-b66a11002158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected epsilon: 1e-06\n",
      "Starting hyperparameter optimisation...\n",
      "[iter 0] avg CV loss: 0.322763\n",
      "lengthscale: tensor([0.1010], grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Getting Cocycle model and predictions\n",
    "\"\"\"\n",
    "# -----------------------------\n",
    "# 1. Load or generate observational and interventional data.\n",
    "# Here we assume:\n",
    "#   X_train: features (shape: (n_train, d)) used for the conditional distribution\n",
    "#   Y_train: 1D tensor of SORTED UNIQUE outcomes (length n_train)\n",
    "#   X_int: features of interventional data (shape: (n_int, d))\n",
    "# (For illustration, we generate synthetic data.)\n",
    "\n",
    "n_train = 5\n",
    "d = 1\n",
    "n_int = 5\n",
    "\n",
    "# Generate synthetic observational data.\n",
    "# (Here we sample uniformly and sort Y_train; your DGP will provide these.)\n",
    "X_train_np = np.random.uniform(0, 1, size=(n_train, d))\n",
    "Y_train_np = np.sort(np.random.uniform(0, 1, size=n_train))  # ensure sorted unique outcomes\n",
    "# Convert to torch tensors.\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train_np, dtype=torch.float64)\n",
    "# Generate interventional features.\n",
    "X_int_np = np.random.uniform(0, 1, size=(n_int, d))\n",
    "X_int = torch.tensor(X_int_np, dtype=torch.float64)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Determine a suitable epsilon.\n",
    "# We choose epsilon to be a fraction (e.g., 1/10) of the smallest gap between successive Y_train values.\n",
    "gaps = Y_train[1:] - Y_train[:-1]\n",
    "min_gap = gaps.min()\n",
    "epsilon = min(min_gap / 10,1e-6)\n",
    "print(\"Selected epsilon:\", epsilon)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Instantiate the NWConditioner.\n",
    "# Here we create a GaussianKernel with an initial lengthscale (you may tune this further or optimize it).\n",
    "kernel = GaussianKernel(lengthscale=torch.ones(d)/10)\n",
    "functional = NWFunctional(kernel=kernel, reg=0.0)\n",
    "CER = ConditionalExpectationRegressor(functional)\n",
    "\n",
    "# The optimiser will use your NWFunctionalâ€™s hyperparameter list, which in this case is [kernel.log_lengthscale].\n",
    "print(\"Starting hyperparameter optimisation...\")\n",
    "test_points = torch.linspace(Y_train.min()-0.1, Y_train.max()+0.1, 100)[:,None]\n",
    "feature = (Y_train[:,None] <= test_points.T).float()\n",
    "losses = CER.optimise(X_train, feature, maxiter=10, nfold=5, learn_rate=1e-2, print_=True,\n",
    "                    subsamples = 512)\n",
    "# -----------------------------\n",
    "# 4. Instantiate the KR transformer layer and NWconditioner.\n",
    "#kernel = GaussianKernel(lengthscale=torch.ones(d)/d**0.5)\n",
    "conditioner = NWConditioner(X_train, kernel)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Instantiate the KR transformer layer.\n",
    "# Y_train is assumed to be sorted and unique.\n",
    "transformer = KREpsLayer(Y_train, epsilon)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Build the KR-cocycle model using the CocycleModel class.\n",
    "# The CocycleModel class (from your uploaded files, e.g. model_builder.py)\n",
    "# is assumed to accept a conditioner and transformer as components.\n",
    "model = CocycleModel(conditioner=conditioner, transformer=transformer)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Compute counterfactual predictions.\n",
    "# The typical API is:\n",
    "#    model.cocycle(X_int, X_train, Y_train)\n",
    "# This function should internally compute weights from the observational features,\n",
    "# learn a mapping via the transformear (using the backward function to get the cumulative probability)\n",
    "# and then apply the forward mapping to the interventional features.\n",
    "cf_predictions = model.cocycle(X_int * 0 + 0.25, X_train * 0 + 0.75, Y_train[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e05eddd-02a6-4b9e-a331-5dd21e4eb055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in predictions: tensor(3.4972e-16, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparing with working KR map\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "weights_int = conditioner(X_int * 0+0.25)\n",
    "weights_train = conditioner(X_train * 0 + 0.75)\n",
    "plt.scatter(weights_train[0].detach(),weights_int[0].detach())\n",
    "KR,F,Q = build_KR_map(Y_train, Y_train, weights_train[0], weights_int[0], epsilon)\n",
    "print(\"Difference in predictions:\",(KR(Y_train[:,None])-cf_predictions).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef3070e-c612-461b-804d-c412f7b58c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in predictions: tensor(3.8550e-13, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparison in continuous input case\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "cf_predictions = model.cocycle(X_int, X_train, Y_train[:,None])\n",
    "weights_int = conditioner(X_int )\n",
    "weights_train = conditioner(X_train)\n",
    "KRpreds = torch.tensor([build_KR_map(Y_train, Y_train, weights_train[i], weights_int[i], epsilon)[0](Y_train[i,None]) for i in range(n_int)])\n",
    "print(\"Difference in predictions:\",(KRpreds-cf_predictions).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288b99bd-a397-4451-a101-c6b98ffb92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Two datasets under binary conditions\n",
    "\"\"\"\n",
    "class AggregateNWConditioner(torch.nn.Module):\n",
    "    def __init__(self, kernels, X_splits, domain_key=\"D\", feature_key=\"X\"):\n",
    "        super().__init__()\n",
    "        self.conditioners = torch.nn.ModuleList([\n",
    "            NWConditioner(X, k) for X, k in zip(X_splits, kernels)\n",
    "        ])\n",
    "        self.domain_key = domain_key\n",
    "        self.feature_key = feature_key\n",
    "        self.n = 0\n",
    "        for split in X_splits:\n",
    "            self.n += len(split)\n",
    "        self.ids = torch.zeros(self.n)\n",
    "        start,end = 0,0\n",
    "        for d in range(len(X_splits)):\n",
    "            end += len(X_splits[d])\n",
    "            self.ids[start:end] = d\n",
    "            start = end\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        X_query = input_dict[self.feature_key]\n",
    "        D_query = input_dict[self.domain_key]\n",
    "        \n",
    "        weights_list = []\n",
    "        for d in range(len(self.conditioners)):\n",
    "            mask = (D_query == d)\n",
    "            if mask.sum() > 0:\n",
    "                theta = self.conditioners[d](X_query[mask])\n",
    "                weights_full = torch.zeros((mask.sum(), self.n), device=theta.device).double()\n",
    "                idx_map = torch.where(self.ids == d)[0]\n",
    "                weights_full[:, idx_map] = theta\n",
    "                weights_list.append((mask, weights_full))\n",
    "\n",
    "        output = torch.zeros((X_query.shape[0], self.n), device=X_query.device).double()\n",
    "        for mask, weighted_block in weights_list:\n",
    "            output[mask] = weighted_block\n",
    "        print(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "n_train = 100\n",
    "d = 1\n",
    "n_int = 100\n",
    "\n",
    "X_train = torch.ones(n_train, dtype=torch.float64).unsqueeze(-1)\n",
    "Y_train = torch.tensor(np.sort(np.random.uniform(0, 1, size=n_train)) , dtype=torch.float64)\n",
    "D_train = torch.zeros(n_train, dtype=torch.float64)\n",
    "\n",
    "X_int = torch.ones(n_train, dtype=torch.float64).unsqueeze(-1)\n",
    "Y_int = torch.tensor(np.sort(np.random.uniform(0, 1, size=n_train)) , dtype=torch.float64)\n",
    "D_int = torch.ones(n_train, dtype=torch.float64)\n",
    "\n",
    "inputs_train = {'X': X_train,\n",
    "                'D': D_train}\n",
    "\n",
    "inputs_int = {'X': X_int,\n",
    "                'D': D_int}\n",
    "\n",
    "X_splits = [X_train,X_int]\n",
    "Y_splits = [Y_train,Y_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8c1a3c-281b-4b2e-9926-778cc65aafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0100, 0.0100, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Difference in predictions: tensor(1.9372e-10, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# working KR map\n",
    "KR_preds = build_KR_map(Y_train, Y_int, epsilon = epsilon)[0](Y_train[:,None])\n",
    "\n",
    "# cocycle\n",
    "conditioner = AggregateNWConditioner([kernel]*2,X_splits)\n",
    "transformer = KREpsLayer(torch.cat(Y_splits), epsilon)\n",
    "model = CocycleModel(conditioner=conditioner, transformer=transformer)\n",
    "cocycle_preds = model.cocycle(inputs_int, inputs_train, Y_train)\n",
    "print(\"Difference in predictions:\",(KR_preds-cocycle_preds).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "731e2bdb-3b1e-4985-a8a5-069834de9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Two datasets but conditional cdfs being used (i.e. KR_{(1,x'),(0,x))(y)\n",
    "\"\"\"\n",
    "n_train = 100\n",
    "d = 1\n",
    "n_int = 100\n",
    "\n",
    "X_train = torch.randn(n_train, dtype=torch.float64).unsqueeze(-1)\n",
    "Y_train = torch.tensor(np.sort(np.random.uniform(0, 1, size=n_train)) , dtype=torch.float64)\n",
    "D_train = torch.zeros(n_train, dtype=torch.float64)\n",
    "mapped_X_train = torch.randn(n_train, dtype=torch.float64).unsqueeze(-1)\n",
    "\n",
    "X_int = torch.randn(n_train, dtype=torch.float64).unsqueeze(-1)\n",
    "Y_int = torch.tensor(np.sort(np.random.uniform(0, 1, size=n_train)) , dtype=torch.float64)\n",
    "D_int = torch.ones(n_train, dtype=torch.float64)\n",
    "\n",
    "inputs_train = {'X': X_train,\n",
    "                'D': D_train}\n",
    "\n",
    "inputs_int = {'X': mapped_X_train,\n",
    "                'D': D_int}\n",
    "\n",
    "X_splits = [X_train,X_int]\n",
    "Y_splits = [Y_train,Y_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d21a790-806a-4301-b40c-bad5e7ef8de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0038e-01, 8.7513e-07, 4.7676e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.3265e-07, 9.5504e-02, 1.4295e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.9636e-02, 1.5642e-04, 1.0450e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [2.2020e-06, 3.5213e-21, 3.6151e-09,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.3757e-48, 1.6926e-22, 9.5710e-41,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.9030e-04, 5.2766e-02, 7.1236e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.2396e-26,\n",
      "          1.7037e-68,  6.1849e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.8989e-68,\n",
      "         3.9139e-131,  2.7459e-09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.1837e-08,\n",
      "          3.4928e-34,  6.5932e-10],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.4199e-11,\n",
      "          1.3883e-01,  7.4017e-74],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.8584e-86,\n",
      "         4.0824e-155,  4.8574e-16],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1351e-01,\n",
      "          1.5590e-11,  6.4881e-31]], dtype=torch.float64,\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "Difference in predictions: tensor(4.9087e-12, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# working KR map\n",
    "conditioner_train = NWConditioner(X_train, kernel)\n",
    "conditioner_int = NWConditioner(X_int, kernel)\n",
    "\n",
    "KR_preds = torch.tensor([build_KR_map(Y_train, Y_int, conditioner_train(X_train[i:i+1,:])[0], conditioner_int(mapped_X_train[i:i+1,:])[0], epsilon = epsilon)[0](Y_train[i,None]) for i in range(n_int)])\n",
    "\n",
    "# cocycle\n",
    "conditioner = AggregateNWConditioner([kernel]*2,X_splits)\n",
    "transformer = KREpsLayer(torch.cat(Y_splits), epsilon)\n",
    "model = CocycleModel(conditioner=conditioner, transformer=transformer)\n",
    "cocycle_preds = model.cocycle(inputs_int, inputs_train, Y_train)\n",
    "print(\"Difference in predictions:\",(KR_preds-cocycle_preds).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375453d0-55bc-4f78-bb3f-32d5a073fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0038e-01, 8.7513e-07, 4.7676e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [8.3265e-07, 9.5504e-02, 1.4295e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.9636e-02, 1.5642e-04, 1.0450e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [2.2020e-06, 3.5213e-21, 3.6151e-09,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.3757e-48, 1.6926e-22, 9.5710e-41,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.9030e-04, 5.2766e-02, 7.1236e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m comp_conditioner \u001b[38;5;241m=\u001b[39m CompositeConditioner(layers \u001b[38;5;241m=\u001b[39m [conditioner])\n\u001b[1;32m      3\u001b[0m model_new \u001b[38;5;241m=\u001b[39m CocycleModel(comp_conditioner,transformer)\n\u001b[0;32m----> 4\u001b[0m cocycle_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcocycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifference in predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m,(KR_preds\u001b[38;5;241m-\u001b[39mcocycle_preds)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m~/Cocycles/causal_cocycle/model_new.py:65\u001b[0m, in \u001b[0;36mCocycleModel.cocycle\u001b[0;34m(self, x1, x2, y)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcocycle\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, y):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation(x1, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Cocycles/causal_cocycle/model_new.py:62\u001b[0m, in \u001b[0;36mCocycleModel.inverse_transformation\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transformation\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[1;32m     61\u001b[0m     transformer_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditioner(x)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cocycles/causal_cocycle/transformers_new.py:410\u001b[0m, in \u001b[0;36mKREpsLayer.backward\u001b[0;34m(self, theta, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m S_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS(diff)  \u001b[38;5;66;03m# shape: (batch, n)\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Compute weighted sum for each batch element.\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m F_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mtheta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS_vals\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape: (batch,)\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_vals\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "from causal_cocycle.conditioners_new import CompositeConditioner\n",
    "comp_conditioner = CompositeConditioner(layers = [conditioner])\n",
    "model_new = CocycleModel(comp_conditioner,transformer)\n",
    "cocycle_preds = model_new.cocycle(inputs_int, inputs_train, Y_train)\n",
    "print(\"Difference in predictions:\",(KR_preds-cocycle_preds).abs().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

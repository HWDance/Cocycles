{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User\n",
    "user = \"nk1922\"\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal,Laplace,Uniform,Gamma\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project/Cocycle_code'.format(user))\n",
    "from Cocycle_CDAGM import *\n",
    "from Cocycle_model import *\n",
    "from Cocycle_optimise import *\n",
    "from Cocycle_loss_functions import *\n",
    "from Conditioners import *\n",
    "from Transformers import *\n",
    "from KDE_estimation import *\n",
    "from Kernels import *\n",
    "from Helper_functions import *\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project/Experiments_code'.format(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental set up\n",
    "trials = 100\n",
    "N,D,P = 100,10,10\n",
    "alpha_X = 0.01\n",
    "alpha_U = 0.01\n",
    "R2 = 0.9\n",
    "\n",
    "# Training set up\n",
    "RFF_features = False\n",
    "n_RFF =100\n",
    "median_heuristic = True\n",
    "train_val_split = 1\n",
    "ntrain = int(train_val_split*N)\n",
    "conditioner_learn_rate = 1e-3\n",
    "transformer_learn_rate = 1e-3\n",
    "scheduler = True\n",
    "val_tol = 1e-3\n",
    "batch_size = N\n",
    "val_loss = False\n",
    "maxiter = 5000\n",
    "miniter = 5000\n",
    "\n",
    "# Object storage\n",
    "names = [\"L2\",\"L1\",\"HSIC\",\"JMMD\",\"CMMD\",\"True\"]\n",
    "Coeffs = torch.zeros((len(names),trials,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "for t in range(trials):\n",
    "    \n",
    "    # Drawing data\n",
    "    torch.manual_seed(t)\n",
    "    X = Gamma(alpha_X,alpha_X**0.5).sample((N,D))-alpha_X**0.5\n",
    "    B = torch.ones((D,1))*(torch.linspace(0,D-1,D)<P)[:,None]\n",
    "    F = X @ B\n",
    "    U = Gamma(alpha_U,alpha_U**0.5).sample((N,1))-alpha_U**0.5\n",
    "    U *= 1/U.var()**0.5*((1-R2)/R2*F.var())**0.5\n",
    "    Y = F + U\n",
    "    print(1-(U**2).mean()/(Y**2).mean())\n",
    "\n",
    "    # Training with L2\n",
    "    LS_model = torch.linalg.solve(X.T @ X, X.T @ Y)\n",
    "\n",
    "    # Training with L1\n",
    "    inputs_train,outputs_train, inputs_val,outputs_val  = X[:ntrain],Y[:ntrain],X[ntrain:],Y[ntrain:]\n",
    "    loss_fn = Loss(loss_fn = \"L1\",kernel = [gaussian_kernel(torch.ones(1),1),gaussian_kernel(torch.ones(1),1)])\n",
    "    if RFF_features:\n",
    "        loss_fn.get_RFF_features(n_RFF)\n",
    "    if median_heuristic:\n",
    "        loss_fn.median_heuristic(X,Y, subsamples = 10**4)\n",
    "    conditioner = Lin_Conditioner(D,1)\n",
    "    transformer = Shift_Transformer()\n",
    "    L1_model = cocycle_model([conditioner],transformer)\n",
    "    L1_model = Train(L1_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                         transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                 scheduler = scheduler)\n",
    "\n",
    "    # Training with HSIC\n",
    "    inputs_train,outputs_train, inputs_val,outputs_val  = X[:ntrain],Y[:ntrain],X[ntrain:],Y[ntrain:]\n",
    "    loss_fn = Loss(loss_fn = \"HSIC\",kernel = [gaussian_kernel(torch.ones(1),1),gaussian_kernel(torch.ones(1),1)])\n",
    "    if RFF_features:\n",
    "        loss_fn.get_RFF_features(n_RFF)\n",
    "    if median_heuristic:\n",
    "        loss_fn.median_heuristic(X,Y, subsamples = 10**4)\n",
    "    conditioner = Lin_Conditioner(D,1)\n",
    "    transformer = Shift_Transformer()\n",
    "    HSIC_model = cocycle_model([conditioner],transformer)\n",
    "    HSIC_model = Train(HSIC_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                         transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                 scheduler = scheduler)\n",
    "\n",
    "    # Training with JMMD\n",
    "    RFF_features = True\n",
    "    inputs_train,outputs_train, inputs_val,outputs_val  = X[:ntrain],Y[:ntrain],X[ntrain:],Y[ntrain:]\n",
    "    loss_fn = Loss(loss_fn = \"JMMD_M_RFF\",kernel = [gaussian_kernel(torch.ones(1),1),gaussian_kernel(torch.ones(1),1)])\n",
    "    if RFF_features:\n",
    "        loss_fn.get_RFF_features(100)\n",
    "    if median_heuristic:\n",
    "        loss_fn.median_heuristic(X,Y, subsamples = 10**4)\n",
    "    conditioner = Lin_Conditioner(D,1)\n",
    "    transformer = Shift_Transformer()\n",
    "    JMMD_model = cocycle_model([conditioner],transformer)\n",
    "    JMMD_model = Train(JMMD_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                         transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                 scheduler = scheduler)\n",
    "\n",
    "    # Training with CMMD\n",
    "    RFF_features = False\n",
    "    inputs_train,outputs_train, inputs_val,outputs_val  = X[:ntrain],Y[:ntrain],X[ntrain:],Y[ntrain:]\n",
    "    loss_fn = Loss(loss_fn = \"CMMD_M\",kernel = [gaussian_kernel(torch.ones(1),1),gaussian_kernel(torch.ones(1),1)])\n",
    "    if RFF_features:\n",
    "        loss_fn.get_RFF_features(n_RFF)\n",
    "    if median_heuristic:\n",
    "        loss_fn.median_heuristic(X,Y, subsamples = 10**4)\n",
    "    conditioner = Lin_Conditioner(D,1)\n",
    "    transformer = Shift_Transformer()\n",
    "    CMMD_model = cocycle_model([conditioner],transformer)\n",
    "    CMMD_model = Train(CMMD_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                         transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                 scheduler = scheduler)\n",
    "    \n",
    "    # Storing results\n",
    "    Coeffs[0,t] = LS_model.T\n",
    "    Coeffs[1,t] = L1_model.conditioner[0].state_dict()['stack.0.weight']\n",
    "    Coeffs[2,t] = HSIC_model.conditioner[0].state_dict()['stack.0.weight']\n",
    "    Coeffs[3,t] = JMMD_model.conditioner[0].state_dict()['stack.0.weight']\n",
    "    Coeffs[4,t] = CMMD_model.conditioner[0].state_dict()['stack.0.weight']\n",
    "    Coeffs[5,t] = CMMD_model.conditioner[0].state_dict()['stack.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving output\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project'.format(user))\n",
    "torch.save({ \"names\": names, \n",
    "            \"Coeffs\": Coeffs},\n",
    "           f = f'Experimental_results/'+'Regression_estimation_testing=N={0}_D={1}_P={2}_R2={3}_alphaX={4}_alphaU={5}_trials={6}.pt'.format(N,D,P,R2,alpha_X,alpha_U,trials)\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

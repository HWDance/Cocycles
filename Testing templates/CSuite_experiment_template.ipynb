{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Csuite data simulation testing template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User\n",
    "user = \"nk1922\"\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal,Laplace,Uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project/Cocycle_code'.format(user))\n",
    "from Cocycle_CDAGM import *\n",
    "from Cocycle_model import *\n",
    "from Cocycle_optimise import *\n",
    "from Cocycle_loss_functions import *\n",
    "from Conditioners import *\n",
    "from Transformers import *\n",
    "from KDE_estimation import *\n",
    "from Kernels import *\n",
    "from Helper_functions import *\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project/Experiments_code'.format(user))\n",
    "from Csuite import Nonlin_Gauss_chain as DGP\n",
    "from Csuite import NonlinGausschain_conditioner as Conditioner\n",
    "#from Csuite import Fork_Nonlin as DGP\n",
    "#from Csuite import Fork_conditioner as Conditioner\n",
    "#from Csuite import Simpson_Nonlin as DGP\n",
    "#from Csuite import Simpson_conditioner as Conditioner\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project/Experimental_results'.format(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental set up\n",
    "parents = [[],[0],[1]]\n",
    "#parents = [[],[],[0,1],[2]]\n",
    "#parents = [[],[0],[0,1],[2]]\n",
    "trials = 1\n",
    "N,Nint = 5000,10**7\n",
    "int_levels = [-2,-1,0,1,2]\n",
    "intervention = lambda a,x : a+x*0\n",
    "quantiles = [0.1,0.5,0.9]\n",
    "adversarial_distribution = False\n",
    "store_quantiles = False\n",
    "gamma_param = 1\n",
    "\n",
    "# Cocycle Estimation set up\n",
    "cocycle_estimators = [\"CLS_M\", \n",
    "                      \"CMMD_M\",\n",
    "                      \"JMMD_M\",\n",
    "                      \"HSIC\"]\n",
    "RFF_features = [False,False,False,False]\n",
    "n_RFF = [100,100,100,100]\n",
    "median_heuristic = [False,True,True,True]\n",
    "\n",
    "# RQS set up\n",
    "RQS_bins = [2,4,8]\n",
    "\n",
    "# MLE set up\n",
    "Gaussian_SCM = True\n",
    "\n",
    "# NN set up\n",
    "train_val_split = 1\n",
    "ntrain = int(train_val_split*N)\n",
    "width = 128\n",
    "layers = 2\n",
    "conditioner_learn_rate = 1e-3\n",
    "transformer_learn_rate = 1e-3\n",
    "scheduler = True\n",
    "val_tol = 1e-3\n",
    "val_loss = False\n",
    "batch_size = 64\n",
    "maxiter = 5000\n",
    "miniter = 5000\n",
    "\n",
    "# KDE set up\n",
    "kde_learn_rate = 0.1\n",
    "kde_miniter = 200\n",
    "kde_maxiter = 1000\n",
    "kde_tol = 1e-4\n",
    "kde_nfold = 5\n",
    "kde_reg = 1e-10\n",
    "\n",
    "# Samples to draw \n",
    "mc_samples = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and dimensions\n",
    "names = ([\"Gaussian SCM\"]+\n",
    "         [\"RQS SCM {0}\".format(i) for i in RQS_bins]+\n",
    "         [\"Cocycles {0}\".format(i) for i in cocycle_estimators]+\n",
    "         [\"Cocycles {0} KDE\".format(i) for i in cocycle_estimators]+\n",
    "         [\"True\"])\n",
    "n_model = len(names)\n",
    "n_int = len(int_levels)\n",
    "n_quantile = len(quantiles)\n",
    "\n",
    "# Storage objects\n",
    "ATE = torch.zeros((n_model,n_int,trials))\n",
    "QTE = torch.zeros((n_model,n_int,trials,n_quantile))\n",
    "E_DO = torch.zeros((n_model,n_int,trials))\n",
    "Q_DO = torch.zeros((n_model,n_int,trials,n_quantile))\n",
    "Training_time = torch.zeros((n_model,trials))\n",
    "\n",
    "# True model construction\n",
    "true_models = []\n",
    "for i in range(len(parents)):\n",
    "    true_models.append(cocycle_model([Conditioner(i)],Shift_Transformer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss last 10 avg is : tensor(-1.3597)\n",
      "Completion % : 99.82\n",
      "iter 0 , loss =  tensor(21932.8242)\n",
      "iter 10 , loss =  tensor(17238.1094)\n",
      "iter 20 , loss =  tensor(15938.0635)\n",
      "iter 30 , loss =  tensor(15938.8281)\n",
      "iter 40 , loss =  tensor(15870.0859)\n",
      "iter 50 , loss =  tensor(15838.0439)\n",
      "iter 60 , loss =  tensor(15831.7393)\n",
      "iter 70 , loss =  tensor(15825.6113)\n",
      "iter 80 , loss =  tensor(15826.5859)\n",
      "iter 90 , loss =  tensor(15825.5918)\n",
      "iter 100 , loss =  tensor(15825.4844)\n",
      "iter 110 , loss =  tensor(15825.4453)\n",
      "iter 120 , loss =  tensor(15825.4316)\n",
      "iter 130 , loss =  tensor(15825.4092)\n",
      "iter 140 , loss =  tensor(15825.4141)\n",
      "iter 150 , loss =  tensor(15825.4141)\n",
      "iter 160 , loss =  tensor(15825.4131)\n",
      "iter 170 , loss =  tensor(15825.4131)\n",
      "iter 180 , loss =  tensor(15825.4092)\n",
      "iter 190 , loss =  tensor(15825.4102)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Initiating trials\n",
    "for t in range(trials):\n",
    "    \n",
    "    torch.manual_seed(t)\n",
    "    \n",
    "    # Draw data\n",
    "    Xobs,Xint = DGP(N, Nint, True, intervention, int_levels, adversarial_distribution, alpha = gamma_param)\n",
    "    Xobs,Xobstest = Xobs[:N],Xobs[N:]\n",
    "    \n",
    "    # Estimate models\n",
    "    ls_models = []\n",
    "    cocycle_models = [[] for i in range(len(cocycle_estimators))]\n",
    "    RQS_models = [[]for i in range(len(RQS_bins))]\n",
    "    \n",
    "    for i in range(len(parents)):\n",
    "        \n",
    "        # Getting relevant variables from graph\n",
    "        index_x,index_y = parents[i],[i]\n",
    "        X,Y = Xobs[:,index_x].view(N,len(index_x)),Xobs[:,index_y].view(N,len(index_y))\n",
    "          \n",
    "        # Data Preprocessing\n",
    "        inputs_train,outputs_train, inputs_val,outputs_val = X[:ntrain],Y[:ntrain],X[ntrain:],Y[ntrain:]\n",
    "\n",
    "        # Defining and training Gaussian SCM\n",
    "        if Gaussian_SCM:\n",
    "            start_time = time.time()\n",
    "            loss_fn = Loss(loss_fn = \"MLE\")\n",
    "            if len(parents[i])>0:\n",
    "                conditioner_shift = NN_Conditioner(width = width, layers = layers, input_dims =  len(index_x), output_dims = len(index_y) ,bias = True)\n",
    "                conditioner_scale = Constant_Conditioner(init = torch.log(outputs_train.var()**0.5/2))\n",
    "            else:\n",
    "                conditioner_shift = Constant_Conditioner(init = outputs_train.mean())\n",
    "                conditioner_scale = Constant_Conditioner(init = torch.log(outputs_train.var()**0.5))\n",
    "            transformer = Affine_Transformer(log_det = True)\n",
    "            ls_model = cocycle_model([conditioner_shift,conditioner_scale],transformer)\n",
    "            ls_model = Train(ls_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                                transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                               scheduler = scheduler)\n",
    "            ls_model.transformer.ld = False # set log determinant to false after\n",
    "            ls_models.append(ls_model)\n",
    "\n",
    "            # Storing training time\n",
    "            Training_time[0,t] +=  time.time() - start_time\n",
    "\n",
    "        # Defining and training cocycle models\n",
    "        if len(parents[i])>0:\n",
    "            for m in range(len(cocycle_estimators)):\n",
    "                start_time = time.time()\n",
    "                loss_fn = Loss(loss_fn = cocycle_estimators[m],kernel = [gaussian_kernel(torch.ones(1),1),gaussian_kernel(torch.ones(1),1)])\n",
    "                if RFF_features[m]:\n",
    "                    loss_fn.get_RFF_features(n_RFF[m])\n",
    "                if median_heuristic[m]:\n",
    "                    if cocycle_estimators[m] == \"HSIC\":\n",
    "                        loss_fn.median_heuristic(inputs_train,outputs_train/2, subsamples = 10**4)\n",
    "                    else:\n",
    "                        loss_fn.median_heuristic(inputs_train,outputs_train, subsamples = 10**4)                        \n",
    "                conditioner = NN_Conditioner(width = width, layers = layers, input_dims =  len(index_x), output_dims = len(index_y) ,bias = True)\n",
    "                transformer = Shift_Transformer()\n",
    "                model = cocycle_model([conditioner],transformer)\n",
    "                model = Train(model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                              transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                                                     scheduler = scheduler)\n",
    "                cocycle_models[m].append(model)\n",
    "                \n",
    "                end_time = time.time()\n",
    "\n",
    "                Training_time[1+len(RQS_bins)+m,t] += end_time - start_time\n",
    "                Training_time[1+len(RQS_bins)+len(cocycle_estimators)+m,t] += end_time - start_time\n",
    "        else:\n",
    "            for m in range(len(cocycle_estimators)):\n",
    "                cocycle_models[m].append([])\n",
    "\n",
    "        # Defining and training RQS flow models\n",
    "        start_time = time.time()\n",
    "        loss_fn = Loss(loss_fn = \"MLE\")\n",
    "        for m in range(len(RQS_bins)):\n",
    "            if len(parents[i])>0:\n",
    "                conditioner = NN_Conditioner(width = width, layers = layers, input_dims =  len(index_x), output_dims = len(index_y) ,bias = True)\n",
    "            else:\n",
    "                conditioner = Empty_Conditioner()\n",
    "            transformer =  RQS_Shift_Transformer(widths = torch.zeros((1,RQS_bins[m]),requires_grad = True),\n",
    "                                   heights = torch.zeros((1,RQS_bins[m]), requires_grad = True),\n",
    "                                   derivatives = torch.zeros((1,RQS_bins[m]+1), requires_grad = True)\n",
    "                                   )\n",
    "            RQS_model = cocycle_model([conditioner],transformer)\n",
    "            RQS_model = Train(RQS_model).optimise(loss_fn,inputs_train,outputs_train,inputs_val,outputs_val, batch_size = batch_size,conditioner_learn_rate = conditioner_learn_rate,\n",
    "                                                  transformer_learn_rate = transformer_learn_rate,print_ = True,plot = False, miniter = miniter,maxiter = maxiter, val_tol = val_tol,val_loss = val_loss,\n",
    "                                                 scheduler = scheduler)\n",
    "            RQS_model.transformer.ld = False # set log determinant to false after\n",
    "            RQS_models[m].append(RQS_model)\n",
    "\n",
    "            Training_time[1+m,t] += time.time() - start_time\n",
    "\n",
    "    # KDE estimation for cocycles\n",
    "    start_time = time.time()\n",
    "    kernel = inverse_gaussian_kernel(torch.ones(len(Xobs.T),requires_grad = True),1)\n",
    "    KDE_model = KDE(kernel)\n",
    "    losses = KDE_model.optimise(Xobs,kde_learn_rate,kde_miniter,kde_maxiter,kde_tol,kde_nfold,kde_reg)\n",
    "    Training_time[1+len(cocycle_estimators)+len(RQS_bins):-1,t] += time.time() - start_time\n",
    "    \n",
    "    # Defining cocycle CDAGMs\n",
    "    ccdagm = []\n",
    "    for m in range(len(cocycle_estimators)):\n",
    "        ccdagm.append(CCDAGM(cocycle_models[m],parents))\n",
    "\n",
    "    # Interventional prediction\n",
    "    print(t)\n",
    "    for i in range(len(int_levels)):\n",
    "        \n",
    "        # Setting intervention level\n",
    "        a = int_levels[i]\n",
    "        \n",
    "        # Getting interventional_samples\n",
    "        Xpred = [],[]\n",
    "        for m in range(n_model):\n",
    "            if m == 0 and Gaussian_SCM:\n",
    "                Xpred,Xintpred = SCM_intervention_sample(parents,ls_models,[Normal(0,1)]*len(parents),intervention,[[\"id\",a,\"id\",\"id\"]],mc_samples)\n",
    "                Xintpred = Xintpred[0]\n",
    "            elif m > 0 and m <= len(RQS_bins):\n",
    "                Xpred,Xintpred = SCM_intervention_sample(parents,RQS_models[m-1],[Normal(0,1)]*len(parents),intervention,[[\"id\",a,\"id\",\"id\"]],mc_samples)\n",
    "                Xintpred = Xintpred[0]\n",
    "            elif m > len(RQS_bins) and m <= len(RQS_bins)+len(cocycle_estimators):\n",
    "                Xpred,Xintpred = ccdagm[m-len(RQS_bins)-1].interventional_dist_sample(Xobs,intervention,[\"id\",a,\"id\",\"id\"],len(Xobs),uniform_subsample = False)\n",
    "            elif m > len(RQS_bins) + len(cocycle_estimators) and m < n_model -1:\n",
    "                Xpred,Xintpred = ccdagm[m-len(RQS_bins)-len(cocycle_estimators)-1].interventional_dist_sample(Xobs,intervention,[\"id\",a,\"id\",\"id\"],mc_samples,density = KDE_model,uniform_subsample = True)\n",
    "            else:\n",
    "                Xpred,Xintpred = Xobstest,Xint[i]\n",
    "                                  \n",
    "            E_DO[m,i,t] = Xintpred[:,-1].mean()\n",
    "            ATE[m,i,t] = E_DO[m,i,t] - Xpred[:,-1].mean()\n",
    "        \n",
    "            if store_quantiles:\n",
    "                k = 0\n",
    "                for q in quantiles:\n",
    "                    Q_DO[m,i,t,k] = Xintpred[:,-1].quantile(q)\n",
    "                    QTE[m,i,t,k] = Q_DO[m,i,t,k] - Xintpred[:,-1].quantile(q)\n",
    "                    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "File Experimental_results/Test_adversarial=True_trials=1_gamma_param=1.pt cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Saving output\u001b[39;00m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hughw/OneDrive/Documents/Cocycles project\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mATE (models x int_levels x trials)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQTE (models x int_levels x trials x quantiles)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQTE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEY|DO(X) (models x int_levels x trials)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_DO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQY|DO(X) (models x int_levels x trials x quantiles)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_DO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining time ( models x trials)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTraining_time\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m           \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m           \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExperimental_results/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest_adversarial=\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m_trials=\u001b[39;49m\u001b[38;5;132;43;01m{1}\u001b[39;49;00m\u001b[38;5;124;43m_gamma_param=\u001b[39;49m\u001b[38;5;132;43;01m{2}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43madversarial_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma_param\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File Experimental_results/Test_adversarial=True_trials=1_gamma_param=1.pt cannot be opened."
     ]
    }
   ],
   "source": [
    "# Saving output\n",
    "os.chdir('C:/Users/{0}/OneDrive/Documents/Cocycles project'.format(user))\n",
    "torch.save({ \"names\": names, \n",
    "            \"ATE (models x int_levels x trials)\": ATE,\n",
    "            \"QTE (models x int_levels x trials x quantiles)\": QTE,\n",
    "            \"EY|DO(X) (models x int_levels x trials)\": E_DO,\n",
    "            \"QY|DO(X) (models x int_levels x trials x quantiles)\": Q_DO,\n",
    "            \"Training time ( models x trials)\": Training_time\n",
    "           },\n",
    "           f = f'Experimental_results/'+'Test_adversarial={0}_trials={1}_gamma_param={2}_batchsize={3}.pt'.format(adversarial_distribution,trials, gamma_param,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0366, 0.0463, 0.0317, 0.0034, 0.0034]) Gaussian SCM\n",
      "tensor([0.0096, 0.0953, 0.0495, 0.0050, 0.0739]) RQS SCM 2\n",
      "tensor([0.0269, 0.0277, 0.0161, 0.0547, 0.0199]) RQS SCM 4\n",
      "tensor([0.0347, 0.0078, 0.0122, 0.0294, 0.0582]) RQS SCM 8\n",
      "tensor([0.0089, 0.0119, 0.0096, 0.0150, 0.0073]) Cocycles CLS_M\n",
      "tensor([0.0434, 0.0393, 0.0170, 0.0827, 0.0495]) Cocycles CMMD_M\n",
      "tensor([0.0049, 0.0211, 0.0151, 0.0430, 0.0385]) Cocycles JMMD_M\n",
      "tensor([0.0014, 0.0380, 0.0528, 0.0997, 0.0850]) Cocycles HSIC\n",
      "tensor([0.0138, 0.0143, 0.0103, 0.0163, 0.0089]) Cocycles CLS_M KDE\n",
      "tensor([0.0453, 0.0384, 0.0217, 0.0840, 0.0540]) Cocycles CMMD_M KDE\n",
      "tensor([0.0037, 0.0174, 0.0110, 0.0455, 0.0424]) Cocycles JMMD_M KDE\n",
      "tensor([0.0049, 0.0393, 0.0523, 0.1024, 0.0922]) Cocycles HSIC KDE\n",
      "tensor([0., 0., 0., 0., 0.]) True\n"
     ]
    }
   ],
   "source": [
    "# Current\n",
    "ints = [0,1,2,3,4]\n",
    "for i in range(n_model):\n",
    "    print ((torch.abs(ATE[i,ints,:t+1]-ATE[-1,ints,:t+1])**2).mean(1)**0.5, names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0165, 0.0427, 0.0197, 0.0297, 0.0818]) Gaussian SCM\n",
      "tensor([0.0596, 0.0625, 0.0208, 0.0455, 0.1094]) RQS SCM 2\n",
      "tensor([0.0052, 0.0531, 0.0200, 0.0372, 0.0107]) RQS SCM 4\n",
      "tensor([0.0142, 0.0149, 0.0351, 0.0058, 0.0230]) RQS SCM 8\n",
      "tensor([0.0210, 0.0338, 0.0419, 0.0574, 0.0411]) Cocycles CLS_M\n",
      "tensor([0.0182, 0.0134, 0.0132, 0.1109, 0.0947]) Cocycles CMMD_M_RFF\n",
      "tensor([0.0223, 0.0012, 0.0526, 0.0574, 0.1265]) Cocycles JMMD_M_RFF\n",
      "tensor([0.0227, 0.0362, 0.0438, 0.0603, 0.0411]) Cocycles CLS_M KDE\n",
      "tensor([0.0197, 0.0141, 0.0157, 0.1124, 0.0963]) Cocycles CMMD_M_RFF KDE\n",
      "tensor([0.0237, 0.0065, 0.0503, 0.0560, 0.1282]) Cocycles JMMD_M_RFF KDE\n",
      "tensor([0., 0., 0., 0., 0.]) True\n"
     ]
    }
   ],
   "source": [
    "# NonlinGauss Gauss\n",
    "ints = [0,1,2,3,4]\n",
    "for i in range(n_model):\n",
    "    print ((torch.abs(ATE[i,ints,:t+1]-ATE[-1,ints,:t+1])**2).mean(1)**0.5, names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2679, 0.5764, 1.0512, 0.8755, 4.2517]) Gaussian SCM\n",
      "tensor([0.4845, 0.2934, 0.4476, 0.3895, 4.1084]) RQS SCM 2\n",
      "tensor([0.5963, 0.2579, 0.4390, 0.3138, 4.5994]) RQS SCM 4\n",
      "tensor([0.2796, 0.3244, 0.2105, 0.4409, 4.5236]) RQS SCM 8\n",
      "tensor([0.3786, 0.0422, 0.0498, 0.1297, 3.9917]) Cocycles CLS_M\n",
      "tensor([0.1821, 0.0924, 0.1078, 0.2357, 4.7863]) Cocycles CMMD_M_RFF\n",
      "tensor([0.2309, 0.0479, 0.0422, 0.3763, 4.4364]) Cocycles JMMD_M_RFF\n",
      "tensor([0.3225, 0.0517, 0.1307, 0.2402, 3.9522]) Cocycles CLS_M KDE\n",
      "tensor([0.1354, 0.0807, 0.0176, 0.3041, 4.6749]) Cocycles CMMD_M_RFF KDE\n",
      "tensor([0.1768, 0.1176, 0.0385, 0.4557, 4.3503]) Cocycles JMMD_M_RFF KDE\n",
      "tensor([0., 0., 0., 0., 0.]) True\n"
     ]
    }
   ],
   "source": [
    "# Fork adverse 1\n",
    "ints = [0,1,2,3,4]\n",
    "for i in range(n_model):\n",
    "    print ((torch.abs(ATE[i,ints,:t+1]-ATE[-1,ints,:t+1])**2).mean(1)**0.5, names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1955, 0.1644, 0.2406, 0.1722, 0.2436]) Gaussian SCM\n",
      "tensor([0.0591, 0.0347, 0.0025, 0.0220, 0.0417]) RQS SCM 2\n",
      "tensor([0.0002, 0.0729, 0.1041, 0.0864, 0.1201]) RQS SCM 4\n",
      "tensor([0.0834, 0.0011, 0.0267, 0.0383, 0.0899]) RQS SCM 8\n",
      "tensor([0.0135, 0.0074, 0.0161, 0.0627, 0.0023]) Cocycles CLS_M\n",
      "tensor([0.0017, 0.0219, 0.0094, 0.0228, 0.0984]) Cocycles CMMD_M_RFF\n",
      "tensor([0.0128, 0.0260, 0.0336, 0.0334, 0.0701]) Cocycles JMMD_M_RFF\n",
      "tensor([0.0123, 0.0094, 0.0141, 0.0594, 0.0004]) Cocycles CLS_M KDE\n",
      "tensor([0.0029, 0.0183, 0.0056, 0.0231, 0.0967]) Cocycles CMMD_M_RFF KDE\n",
      "tensor([0.0143, 0.0247, 0.0342, 0.0350, 0.0709]) Cocycles JMMD_M_RFF KDE\n",
      "tensor([0., 0., 0., 0., 0.]) True\n"
     ]
    }
   ],
   "source": [
    "# NonlinG adverse 1\n",
    "ints = [0,1,2,3,4]\n",
    "for i in range(n_model):\n",
    "    print ((torch.abs(ATE[i,ints,:t+1]-ATE[-1,ints,:t+1])**2).mean(1)**0.5, names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
